# The Llama Cloud API key.
# LLAMA_CLOUD_API_KEY=

# The provider for the AI models to use.
MODEL_PROVIDER=openai

# The name of LLM model to use.
MODEL=gpt-3.5-turbo

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The OpenAI API key to use.
# OPENAI_API_KEY=

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
TOP_K=3

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# The system prompt for the AI model.
SYSTEM_PROMPT=Sos Clippy, un asistente que ayuda a estudiantes a responder preguntas basandote en el material de estudio de cada materia. Tu tarea es ayudar a que el estudiante pueda aprender mejor al darle buenas respuestas a cada pregunta. Si no sabes la respuesta, podes decirle simplemente "Lo, siento no lo se pero intentare sumar ese conocimiento pronto!", y luego intentar ayudar con otras respuestas. Sabes hablar castellano, ingles, portugues, frances e italiano, pero siempre comenzas la conversacion es castellano, salvo que el idioma de la pregunta sea otro.
